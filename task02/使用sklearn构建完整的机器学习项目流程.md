#  使用sklearn构建完整的机器学习项目流程

一般来说，一个完整的机器学习项目分为以下步骤：

- 明确项目任务：回归/分类
- 收集数据集并选择合适的特征。
- 选择度量模型性能的指标。
- 选择具体的模型并进行训练以优化模型。
- 评估模型的性能并调参。

## **2.1 使用sklearn构建完整的回归项目**

(1) **收集数据集并选择合适的特征**

​		根据不同业务场景会有不同的数据源，我们在进行项目前会根据任务来收集数据，并根据业务来拟定特征。在这里我们是使用了boston房屋价格的数据进行练习。

```python
from sklearn import datasets
boston = datasets.load_boston()     # 返回一个类似于字典的类
X = boston.data
y = boston.target
features = boston.feature_names
boston_data = pd.DataFrame(X,columns=features)
boston_data["Price"] = y
boston_data.head()
```

<img src="/Users/jiahongxie/Desktop/GitHub/Ensemble_Learning/pic/1616069246724.jpg" alt="1616069246724" style="zoom:46%;" />

(2) **选择度量模型性能的指标** 

​		观察数据之后，我们会根据业务的需求来拟定不同的指标来衡量模型的性能优劣。以下是常用的回归类衡量指标：

- MSE均方误差：$\text{MSE}(y, \hat{y}) = \frac{1}{n_\text{samples}} \sum_{i=0}^{n_\text{samples} - 1} (y_i - \hat{y}_i)^2.$

   - MAE平均绝对误差:$\text{MAE}(y, \hat{y}) = \frac{1}{n_{\text{samples}}} \sum_{i=0}^{n_{\text{samples}}-1} \left| y_i - \hat{y}_i \right|$

   - $R^2$决定系数：$R^2(y, \hat{y}) = 1 - \frac{\sum_{i=1}^{n} (y_i - \hat{y}_i)^2}{\sum_{i=1}^{n} (y_i - \bar{y})^2}$

   - 解释方差得分:$explained\_{}variance(y, \hat{y}) = 1 - \frac{Var\{ y - \hat{y}\}}{Var\{y\}}$

     

(3) 选择具体的模型并进行训练

​		对于这个数据我们可以尝试使用简单的线性模型来进行回归预测

​																			$$y = WX + b$$

```python

from sklearn.linear_model import LinearRegression
reg = LinearRegression().fit(X, y)
reg.score(X, y)
```

​		或者使用回归树来实现，从根节点开始，对样本的某一特征进行测试，根据测试结果，将样本分配到其子结点；这时，每一个子节点对应着该特征的一个取值。如此递归地对样本进行测试并分配，直至到达叶结点。

```python
from sklearn.tree import DecisionTreeRegressor    
reg_tree = DecisionTreeRegressor(criterion = "mse",min_samples_leaf = 5)
reg_tree.fit(X,y)
reg_tree.score(X,y)
```



(4) 优化基础模型

​	关于梯度：

一般来说，当我们在训练的时候，需要根据预测值不停的拟合目标值，这时候需要使用优化函数对模型进行优化。一般对于梯度的优化算法有**随即梯度下降**、**批量梯度下降**、**自适应梯度下降**等。不同的算法有着不同的特点，应该根据实际情况来选择：

​		**随即梯度下降** ：随机选择一个梯度作为全局梯度的更新，这样的做法可以是梯度的下降速度变快，但是也容易落到鞍点

​		**批量梯度下降**：选择一批两样本的梯度的平均值作为更新值，这样的下降方式更为保守，在追寻速度的同时也降低了落入按点的可能性

​		**自适应梯度下降**：之前两种都有一个明显的缺点，就是每个特征的梯度都按照一样的速率下降，有可能导致一些梯度大的下降速度过慢，或者一些本身梯度小的特征下降过快，所以使用自适应梯度下降可以很好的缓解这个问题

​	关于参数调整：

​		调整超参数是一个非常需要经验的事情，在毫无头绪的时候，可以尝试使用网格搜索gridsearch对超参数进行一定范围内的搜索。但是当样本量巨大的时候，这个往往非常的耗时及消耗计算资源。所以对于简单模型的超参数调整一般是根据个人经验先预设一个初始值，再根据训练集合的表现来适当调整部分超参数。

​		如果是过拟合，可以尝试降低模型的复杂程度并提高正则项的系数；欠拟合就适当增加模型复杂程度，比如树模型的深度，叶子结点的个数等。

## 2.2 使用sklearn构建完整的分类项目

(1) **收集数据集并选择合适的特征**：在数据集上我们使用我们比较熟悉的IRIS鸢尾花数据集。

```python
from sklearn import datasets
iris = datasets.load_iris()
X = iris.data
y = iris.target
feature = iris.feature_names
data = pd.DataFrame(X,columns=feature)
data['target'] = y
data.head()
```

<img src="/Users/jiahongxie/Desktop/GitHub/Ensemble_Learning/pic/1616077792677.jpg" alt="1616077792677" style="zoom:50%;" />

(2) **选择度量模型性能的指标**：

​		度量分类模型的指标和回归的指标有很大的差异，首先是因为分类问题本身的因变量是离散变量，因此像定义回归的指标那样，单单衡量预测值和因变量的相似度可能行不通。其次，在分类任务中，我们对于每个类别犯错的代价不尽相同，例如：我们将癌症患者错误预测为无癌症和无癌症患者错误预测为癌症患者，在医院和个人的代价都是不同的，前者会使得患者无法得到及时的救治而耽搁了最佳治疗时间甚至付出生命的代价，而后者只需要在后续的治疗过程中继续取证就好了，因此我们很不希望出现前者，当我们发生了前者这样的错误的时候会认为建立的模型是很差的。为了解决这些问题，我们必须将各种情况分开讨论，然后给出评价指标。

分类模型的指标：                    
   - 准确率：分类正确的样本数占总样本的比例，即：$ACC = \frac{TP+TN}{FP+FN+TP+TN}$.                                
   - 精度：预测为正且分类正确的样本占预测值为正的比例，即：$PRE = \frac{TP}{TP+FP}$.                     
   - 召回率：预测为正且分类正确的样本占类别为正的比例，即：$REC =  \frac{TP}{TP+FN}$.                     
   - F1值：综合衡量精度和召回率，即：$F1 = 2\frac{PRE\times REC}{PRE + REC}$.                                     
   - ROC曲线：以假阳率为横轴，真阳率为纵轴画出来的曲线，曲线下方面积越大越好。

在在不同的业务中，我们**不能光按照一个指标来衡量模型的好坏**，因为不同类型的业务所需要的指标不一样，比如异常值检测和推荐内容的排序所选择的指标因该是不一样的。因为异常值检测需要找到异常的样本，那么根据**准确率**来衡量的话，因为异常值毕竟是少数，无论怎么训练这个指标都会表现的很好。所以我们需要考虑别的指标来衡量模型的优劣。

(3) **选择具体的模型并进行训练**

​		一般来说我们对数据进行训练的时候会找一个**基模型**来作为一个baseline，然后再利用不同的模型迭代比较这个baseline。比baseline效果好的才能用来替换现有模型。最开始我们可以考虑**逻辑回归**，因为这个模型属于广义线性模型，具有可解释性强，训练资源消耗也不大的优点，并且在线上也方便部署。

​		随着我们对特征工程的深入和对模型性能的追求，可以考虑树模型，或者深度学习模型来进行分类。树模型的好处在于可以对特征做自动组合，从而省去了人工特征工程的工作量。在数据量加大的时候，可利用DNN来挖掘更多特征潜在的关系。

